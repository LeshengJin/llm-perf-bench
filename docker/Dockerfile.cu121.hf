# NOTE: This Dockerfile is based on CUDA 12.1.
# To benchmark on other CUDA versions, search and replace "12.1" and "121".
FROM nvidia/cuda:12.1.1-devel-ubuntu22.04

SHELL ["/bin/bash", "-ec"]

# Step 1. Set up Ubuntu
RUN grep -v '[ -z "\$PS1" ] && return' ~/.bashrc >/tmp/bashrc                               && \
    echo "alias conda=micromamba" >>/tmp/bashrc                                             && \
    mv /tmp/bashrc ~/.bashrc

RUN apt update                                                                              && \
    apt install --yes wget curl git vim build-essential openssh-server cmake

# Step 2. Set up python
RUN bash <(curl -L micro.mamba.pm/install.sh) && source ~/.bashrc                                           && \
    micromamba create --yes -n python311 -c conda-forge                                                        \
    python=3.11                                                                                             && \
    micromamba activate python311                                                                           && \
    pip install transformers==4.33.3 torch==2.0.1 accelerate==0.23.0 bitsandbytes==0.41.1 scipy==1.11.3

